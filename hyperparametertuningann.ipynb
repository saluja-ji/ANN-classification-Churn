{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the optimal number of hidden layers and neurons for an Artificial Neural Network (ANN)\n",
    "\n",
    "This can be challanging nd often require experimeentation. However some guidelines can be followed\n",
    "\n",
    "* Start Simple: Begin with a simple architecture and gradually increase complexity if needed.\n",
    "* Grid Search/Random Search: Use grid or random search to try different architecture \n",
    "* Cross-Validation: Use cross-validation to evaluate performance of different architecture \n",
    "* Heuristics and rule of thumb: Some heuristic and empherical rule can provide starting point,\n",
    "     - The numeber of neurons in the hidden layer should be between the size of the input layer and the size of output layer \n",
    "    - A common practise is to start with 1-2 hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoder = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoder_df = pd.DataFrame(geo_encoder, columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "\n",
    "data = pd.concat([data.drop('Geography', axis=1), geo_encoder_df], axis=1)\n",
    "\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the encoder and scaler for later use\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)    \n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fucntion to create the model and try different parameters(KerasClassifier)\n",
    "\n",
    "def create_model(neurons=32,layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keras classifier \n",
    "\n",
    "model = KerasClassifier(layers=1, neurons=32, build_fn = create_model, epochs=50, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define grid search parameter\n",
    "param_grid = {\n",
    "    'neurons' : [16,32,64,128],\n",
    "    'layers' : [1,2],\n",
    "    'epochs' : [50,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfrom grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# print the best parameters\n",
    "print(\"Best: %f using %s\"% (grid_result.best_score_,grid_result.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
